# OadinClient (.NET SDK)

[English](./README.md) | [ç®€ä½“ä¸­æ–‡]

---

## âœ¨ æ¦‚è¿°
**OadinClient** æ˜¯ä¸ Oadin å¹³å°äº¤äº’çš„å®˜æ–¹ .NET SDKã€‚  
æœ¬ README è®°å½•äº†å¦‚ä½•ä½¿ç”¨æœ¬åœ° NuGet æºå®‰è£…åŒ…ï¼Œå¹¶å®Œæ•´å±•ç¤ºå…¨éƒ¨ API ç¤ºä¾‹ã€‚

---

## ğŸ“¦ æœ¬åœ°æºæ·»åŠ æ­¥éª¤
```bash
dotnet pack --configuration Release  

mkdir local-nuget

cp ./bin/Release/OadinClient.1.0.0.nupkg ./local-nuget

# è¿™ä¸€æ­¥ä¼šæŠŠè¿™ä¸ªç›®å½•é…ç½®åˆ° dotnet æºåˆ—è¡¨ä¸­
# dotnet nuget list source å¯ä»¥æŸ¥çœ‹å½“å‰æ‰€æœ‰æº
# ä¹‹ååœ¨ä»»ä½•é¡¹ç›®ä¸­å¯é€šè¿‡ --source LocalOadin å¼•ç”¨è¯¥åŒ…
dotnet nuget add source ./local-nuget --name LocalOadin

dotnet add package OadinClient --version 1.0.0 --source LocalOadin
dotnet add package OadinClient --version 1.0.0 --source .
```

---

## ğŸ§‘â€ğŸ’» å®Œæ•´ API ç¤ºä¾‹
```csharp
using OadinClient;

var client = new OadinClient();


// è·å–æœåŠ¡åˆ—è¡¨
var services = await client.GetServicesAsync();
Console.WriteLiine(services);

// åˆ›å»ºæœåŠ¡
var requestData = new
{
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    service_provider_name = "local_ollama_chat",
    api_flavor = "ollama/openai/...",
    auth_type = "none/apikey/token/credentials",
    method = "GET/POST",
    desc = "æœåŠ¡æè¿°",
    url = "",
    auth_key = "your_api_key",
    skip_model = false,
    model_name = "llama2",
};
var result = await client.InstallServiceAsync(requestData);
Console.WriteLine(result);

// æ›´æ–°æœåŠ¡
var requestData = new
{
    service_name = "chat/embed/generate	text-to-image",
    hybrid_policy = "default/always_local/always_remote",
    remote_provider = "remote_openai_chat",
    local_provider = "local_ollama_chat"
};
var result = await client.UpdateServiceAsync(requestData);
Console.WriteLine(result);

// æŸ¥çœ‹æ¨¡å‹
var models = await client.GetModelsAsync();
Console.WriteLine(models);

// ä¸‹è½½æ¨¡å‹
var requestData = new
{
    model_name = "llama2",
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    provider_name = "local_ollama_chat/remote_openai_chat/..."
};
var result = await client.InstallModelAsync(requestData);
Console.WriteLine(result);

// æµå¼ä¸‹è½½æ¨¡å‹
var requestData = new
{
    model_name = "nomic-embed-text",
    service_name = "embed",
    service_source = "local",
    provider_name = "local_ollama_embed"
};
await client.InstallModelStreamAsync(
    requestData,
    onData: (json) => Console.WriteLine("æµæ•°æ®: " + json),
    onError: (error) => Console.WriteLine("é”™è¯¯: " + error),
    onEnd: () => Console.WriteLine("æµå¼å®‰è£…å®Œæˆ")
);

// å–æ¶ˆæµå¼ä¸‹è½½æ¨¡å‹
var requestData = new
{
    model_name = "nomic-embed-text"
};
await client.CancelInstallModelAsync(requestData);

// å¸è½½æ¨¡å‹
var requestData = new
{
    model_name = "llama2",
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    provider_name = "local_ollama_chat/remote_openai_chat/..."
};
var result = await client.DeleteModelAsync(requestData);
Console.WriteLine(result);

// æŸ¥çœ‹æœåŠ¡æä¾›å•†
var serviceProviders = await client.GetServiceProvidersAsync();
Console.WriteLine(serviceProviders);

// æ–°å¢æ¨¡å‹æä¾›å•†
var requestData = new
{
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    flavor_name = "ollama/openai/...",
    provider_name = "local_ollama_chat/remote_openai_chat/...",
    desc = "æä¾›å•†æè¿°",
    method = "GET/POST",
    url = "https://api.example.com",
    auth_type = "none/apikey/token/credentials",
    auth_key = "your_api_key",
    models = new[] { "qwen2:7b", "deepseek-r1:7b" },
    extra_headers = new { },
    extra_json_body = new {  },
    properties = new { }
};
var result = await client.AddServiceProviderAsync(requestData);
Console.WriteLine(result);

// æ›´æ–°æ¨¡å‹æä¾›å•†
var requestData = new
{
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    flavor_name = "ollama/openai/...",
    provider_name = "local_ollama_chat/remote_openai_chat/...",
    desc = "æ›´æ–°åçš„æè¿°",
    method = "GET/POST",
    url = "https://api.example.com",
    auth_type = "none/apikey/token/credentials",
    auth_key = "your_api_key",
    models = new[] { "qwen2:7b", "deepseek-r1:7b" },
    extra_headers = new { },
    extra_json_body = new {  },
    properties = new { }
};
var result = await client.UpdateServiceProviderAsync(requestData);

// åˆ é™¤æ¨¡å‹æä¾›å•†
var requestData = new
{
    provider_name = "local_ollama_chat/remote_openai_chat/..."
};
var result = await client.DeleteServiceProviderAsync(requestData);

// è·å–æ¨¡å‹åˆ—è¡¨(ä»å¼•æ“)
var models = await client.GetModelAvailiableAsync();
Console.WriteLine(models);

// è·å–æ¨èæ¨¡å‹åˆ—è¡¨
var models = await client.GetModelRecommendedAsync();
Console.WriteLine(models);

// è·å–æ”¯æŒæ¨¡å‹åˆ—è¡¨
var models = await client.GetModelSupportedAsync();
Console.WriteLine(models);

// è·å–é—®å­¦å¹³å°æ¨¡å‹åˆ—è¡¨
var requestData = new
{
    env_type = "dev/product",
};
var models = await client.GetModelListAsync(requestData);
Console.WriteLine(models);

// å¯¼å…¥é…ç½®æ–‡ä»¶
var result = await client.ImportConfigAsync("path/to/.oadin");
Console.WriteLine(result);

// å¯¼å‡ºé…ç½®æ–‡ä»¶
var result = await client.ExportConfigAsync();
Console.WriteLine(result);

// æµå¼ Chat
var requestData = new { 
    model = "deepseek-r1:7b", 
    stream = true,
    messages = new[] { 
        new { role = "user", content = "ä½ æ˜¯è°ï¼Ÿ" } 
    }
};
await client.ChatAsync(
    requestData,
    isStream: true,
    onData: (data) => Console.WriteLine("æµæ•°æ®: " + data),
    onError: (error) => Console.WriteLine("é”™è¯¯: " + error),
    onEnd: () => Console.WriteLine("æµå¼è¯·æ±‚ç»“æŸ")
);

// éæµå¼ Chat
var requestData = new { 
    model = "deepseek-r1:7b", 
    stream = false,
    messages = new[] { 
        new { role = "user", content = "ä½ æ˜¯è°ï¼Ÿ" } 
    }
};
var result = await client.ChatAsync(requestData);
Console.WriteLine(result);

// embed
var requestData = new { 
    model = "nomic-embed-text",
    imput = new[] { 
        "äºŒå½ªå­", 
        "è¸¹çš®" 
    },
};
var result = await client.EmbedAsync(requestData);
Console.WriteLine(result);

// text-to-image
var requestData = new { 
    model = "wanx2.1-t2i-turbo",
    prompt = "å–œæ¬¢ç©åŸƒå¾·åŠ è¹²è‰é‡Œæ”’å¤§æ‹›çš„å°å­¦ç”Ÿ"
};
var result = await client.TextToImageAsync(requestData);
Console.WriteLine(result);
```
